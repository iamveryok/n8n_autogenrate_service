import asyncio
import os
import json
import re

import aiohttp
import json5
from typing import Dict, List, Optional
from dotenv import load_dotenv
from langchain_openai.chat_models.base import BaseChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import logging

from pydantic import BaseModel
from tenacity import retry, stop_after_attempt, wait_exponential
from jsonschema import validate, ValidationError
from dataclasses import dataclass
from datetime import datetime
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


@dataclass
class ErrorPattern:
    error_pattern: str
    solution: str
    priority: int = 1


class ValidationResult(BaseModel):
    is_valid: bool
    errors: List[str] = []
    warnings: List[str] = []

    def __bool__(self):
        return self.is_valid and not self.errors


class AgentState(BaseModel):
    user_input: str
    workflow_json: str
    deployment_result: Dict
    error_messages: List[str]
    iteration_count: int
    max_iterations: int
    validation_results: List[ValidationResult]
    current_stage: str


class N8NWorkflowAgent:
    def __init__(self):
        self.llm = BaseChatOpenAI(
            model="deepseek-chat",
            openai_api_key='sk-d55e63ecb0534036972a3fe3e1370687',  # æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥
            openai_api_base='https://api.deepseek.com',
            temperature=0.1
        )

        # n8n APIé…ç½®
        self.n8n_base_url = os.getenv("N8N_BASE_URL", "http://localhost:5678")
        self.n8n_api_key = os.getenv("N8N_API_KEY")

        # é”™è¯¯æ¨¡å¼åº“
        self.error_patterns = self._initialize_error_patterns()

        # éªŒè¯ç¼“å­˜
        self.validation_cache: Dict[str, ValidationResult] = {}

        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = self._create_system_prompt()

        # n8n JSON Schema
        self.n8n_schema = self._create_n8n_schema()

        # åŠ è½½èŠ‚ç‚¹é…ç½®æ–‡ä»¶
        print("æ­£åœ¨åŠ è½½node_config.jsonæ–‡ä»¶...")
        self.base_nodes = self.load_base_nodes()
        print(f"æˆåŠŸåŠ è½½ {len(self.base_nodes)} ä¸ªèŠ‚ç‚¹è§„èŒƒ")

        # ğŸ”µ å…³é”®ï¼šç¦ç”¨SSLï¼ˆn8næœ¬åœ°éƒ¨ç½²é»˜è®¤ç”¨HTTPï¼Œæ— éœ€åŠ å¯†ï¼‰
        self.connector = aiohttp.TCPConnector(
            limit=10,  # æ§åˆ¶æœ€å¤§è¿æ¥æ•°
            enable_cleanup_closed=True,  # è‡ªåŠ¨æ¸…ç†å…³é—­çš„è¿æ¥
            ssl=False  # æ˜ç¡®ç¦ç”¨SSLï¼Œè§£å†³é…ç½®å†²çª
        )
        # åˆ›å»ºå…¨å±€ä¼šè¯ï¼ˆå¤ç”¨è¿æ¥æ± ï¼‰
        self.session = aiohttp.ClientSession(
            connector=self.connector,
            timeout=aiohttp.ClientTimeout(total=30),
            connector_owner=False  # ä¼šè¯ä¸æ‹¥æœ‰è¿æ¥æ± ï¼Œé¿å…æå‰å…³é—­
        )


    def load_base_nodes(self) -> Dict:
        """åŠ è½½node_config.jsonæ–‡ä»¶"""
        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            base_node_path = os.path.join(base_dir, 'nodes_config.json')
            print(f"  è¯»å–node_config.jsonæ–‡ä»¶: {base_node_path}")
            with open(base_node_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            nodes = data.get('nodes', [])
            print(f"  è§£æåˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹å®šä¹‰")
            # æ„å»ºèŠ‚ç‚¹ç±»å‹æ˜ å°„
            node_dict = {node['type']: node for node in nodes}
            print(f"  æ„å»ºèŠ‚ç‚¹ç±»å‹æ˜ å°„ï¼Œå…± {len(node_dict)} ä¸ªå”¯ä¸€èŠ‚ç‚¹ç±»å‹")
            # æ˜¾ç¤ºä¸€äº›èŠ‚ç‚¹ç±»å‹ç¤ºä¾‹
            sample_types = list(node_dict.keys())[:5]
            print(f"  èŠ‚ç‚¹ç±»å‹ç¤ºä¾‹: {sample_types}")
            return node_dict
        except FileNotFoundError:
            print("æ‰¾ä¸åˆ°node_config.jsonæ–‡ä»¶")
            return {}
        except json.JSONDecodeError as e:
            print(f"node_config.jsonæ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            return {}
        except Exception as e:
            print(f"åŠ è½½node_config.jsonå¤±è´¥: {e}")
            return {}

    def _initialize_error_patterns(self) -> List[ErrorPattern]:
        """åˆå§‹åŒ–é”™è¯¯æ¨¡å¼åº“"""
        return [
            ErrorPattern(
                error_pattern=r"JSON.*(invalid|parse|syntax)",
                solution="ä¿®å¤JSONè¯­æ³•é”™è¯¯ï¼Œç¡®ä¿å¼•å·ã€æ‹¬å·åŒ¹é…ï¼Œé€—å·ä½¿ç”¨æ­£ç¡®",
                priority=1
            ),
            ErrorPattern(
                error_pattern=r"node.*not.*found|unknown.*node",
                solution="æ£€æŸ¥èŠ‚ç‚¹ç±»å‹æ˜¯å¦æ­£ç¡®ï¼Œä½¿ç”¨æœ‰æ•ˆçš„n8nèŠ‚ç‚¹ç±»å‹å¦‚'n8n-nodes-base.httpRequest'",
                priority=1
            ),
            ErrorPattern(
                error_pattern=r"connection.*invalid|missing.*connection",
                solution="ç¡®ä¿connectionså­—æ®µæ­£ç¡®è¿æ¥èŠ‚ç‚¹ï¼Œæ£€æŸ¥èŠ‚ç‚¹IDå¼•ç”¨æ˜¯å¦æ­£ç¡®",
                priority=2
            ),
            ErrorPattern(
                error_pattern=r"position.*required|missing.*position",
                solution="ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ positionå­—æ®µï¼Œæ ¼å¼ä¸º[x, y]",
                priority=2
            ),
            ErrorPattern(
                error_pattern=r"typeVersion.*required",
                solution="ä¸ºæ‰€æœ‰èŠ‚ç‚¹æ·»åŠ typeVersionå­—æ®µï¼Œé€šå¸¸ä¸º1æˆ–1.2",
                priority=2
            ),
            ErrorPattern(
                error_pattern=r"credential.*missing|authentication",
                solution="ä¸ºéœ€è¦è®¤è¯çš„èŠ‚ç‚¹æ·»åŠ credentialså­—æ®µï¼Œæˆ–ç¡®ä¿è®¤è¯é…ç½®æ­£ç¡®",
                priority=3
            ),
            ErrorPattern(
                error_pattern=r"parameter.*missing|invalid.*parameter",
                solution="æ£€æŸ¥èŠ‚ç‚¹å‚æ•°æ˜¯å¦å®Œæ•´ï¼Œç¡®ä¿å¿…éœ€å‚æ•°éƒ½å­˜åœ¨",
                priority=2
            )
        ]

    def _create_system_prompt(self) -> str:
        """åˆ›å»ºç³»ç»Ÿæç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸€ä¸ªn8nå·¥ä½œæµä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆç¬¦åˆn8nè§„èŒƒçš„JSONå·¥ä½œæµã€‚

å½“å‰æ—¶é—´: {datetime.now().isoformat()}

n8nå·¥ä½œæµè§„èŒƒè¦æ±‚ï¼š
1. å¿…é¡»åŒ…å«nameã€nodesã€connectionsã€settingsã€versionIdç­‰åŸºæœ¬å­—æ®µ
2. nodesæ•°ç»„ä¸­æ¯ä¸ªèŠ‚ç‚¹å¿…é¡»æœ‰idã€nameã€typeã€typeVersionã€positionã€parameters
3. connectionså¿…é¡»æ­£ç¡®è¿æ¥å„ä¸ªèŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹ä¹‹é—´éœ€è¦å»ºç«‹æ­£ç¡®çš„è¿æ¥å…³ç³»
4. æ‰€æœ‰èŠ‚ç‚¹typeå¿…é¡»ä½¿ç”¨æ­£ç¡®çš„n8nèŠ‚ç‚¹ç±»å‹
5. ç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ï¼Œä½¿ç”¨åŒå¼•å·
6. positionæ ¼å¼ä¸º[x, y]æ•°ç»„
7. typeVersioné€šå¸¸ä¸º1æˆ–1.2

å¸¸è§èŠ‚ç‚¹ç±»å‹ï¼š
- n8n-nodes-base.scheduleTrigger (å®šæ—¶è§¦å‘å™¨)
- n8n-nodes-base.httpRequest (HTTPè¯·æ±‚)
- n8n-nodes-base.code (ä»£ç èŠ‚ç‚¹)
- n8n-nodes-base.function (å‡½æ•°èŠ‚ç‚¹)
- n8n-nodes-base.emailSend (é‚®ä»¶å‘é€)

é”™è¯¯æ¨¡å¼åº“çŸ¥è¯†ï¼š
{self._get_error_patterns_knowledge()}

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„å·¥ä½œæµJSONã€‚ç¡®ä¿è¯­æ³•æ­£ç¡®ä¸”ç¬¦åˆn8nè§„èŒƒã€‚"""

    def _get_error_patterns_knowledge(self) -> str:
        """è·å–é”™è¯¯æ¨¡å¼åº“çŸ¥è¯†"""
        knowledge = []
        for pattern in sorted(self.error_patterns, key=lambda x: x.priority, reverse=True):
            knowledge.append(f"- é”™è¯¯æ¨¡å¼: {pattern.error_pattern}")
            knowledge.append(f"  è§£å†³æ–¹æ¡ˆ: {pattern.solution}")
        return "\n".join(knowledge)

    def _create_n8n_schema(self) -> Dict:
        """åˆ›å»ºn8n JSON Schemaç”¨äºéªŒè¯"""
        return {
            "type": "object",
            "required": ["name", "nodes", "connections"],
            "properties": {
                "name": {"type": "string"},
                "nodes": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["id", "name", "type", "typeVersion", "position", "parameters"],
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "type": {"type": "string"},
                            "typeVersion": {"type": ["number", "string"]},
                            "position": {
                                "type": "array",
                                "items": {"type": "number"},
                                "minItems": 2,
                                "maxItems": 2
                            },
                            "parameters": {"type": "object"}
                        }
                    }
                },
                "connections": {"type": "object"},
                "settings": {"type": "object"},
                "versionId": {"type": "string"},
                "active": {"type": "boolean"}
            }
        }

    def _get_workflow_hash(self, workflow_json: str) -> str:
        """è·å–å·¥ä½œæµå“ˆå¸Œå€¼ç”¨äºç¼“å­˜"""
        return hashlib.md5(workflow_json.encode()).hexdigest()

    def validate_syntax(self, workflow_json: str) -> ValidationResult:
        """è¯­æ³•éªŒè¯ï¼šJSONæ ¼å¼æ£€æŸ¥"""
        workflow_hash = self._get_workflow_hash(workflow_json)

        if workflow_hash in self.validation_cache:
            return self.validation_cache[workflow_hash]

        errors = []
        warnings = []

        try:
            # å°è¯•è§£æJSON
            data = json5.loads(workflow_json)

            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not isinstance(data, dict):
                errors.append("å·¥ä½œæµå¿…é¡»æ˜¯JSONå¯¹è±¡")

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ["name", "nodes", "connections"]
            for field in required_fields:
                if field not in data:
                    errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

            result = ValidationResult(
                is_valid=len(errors) == 0,
                errors=errors,
                warnings=warnings
            )
            self.validation_cache[workflow_hash] = result
            return result

        except json.JSONDecodeError as e:
            error_msg = f"JSONè¯­æ³•é”™è¯¯: {str(e)}"
            result = ValidationResult(is_valid=False, errors=[error_msg])
            self.validation_cache[workflow_hash] = result
            return result

    def validate_schema(self, workflow_json: str) -> ValidationResult:
        """æ¨¡å¼éªŒè¯ï¼šn8n Schemaæ£€æŸ¥"""
        workflow_hash = self._get_workflow_hash(workflow_json)

        if workflow_hash in self.validation_cache and self.validation_cache[workflow_hash].errors:
            return self.validation_cache[workflow_hash]

        errors = []
        warnings = []

        try:
            data = json5.loads(workflow_json)

            # ä½¿ç”¨jsonschemaéªŒè¯
            validate(instance=data, schema=self.n8n_schema)

            # é¢å¤–è‡ªå®šä¹‰éªŒè¯
            self._custom_validation(data, errors, warnings)

            result = ValidationResult(
                is_valid=len(errors) == 0,
                errors=errors,
                warnings=warnings
            )
            self.validation_cache[workflow_hash] = result
            return result

        except ValidationError as e:
            errors.append(f"SchemaéªŒè¯é”™è¯¯: {e.message}")
            result = ValidationResult(is_valid=False, errors=errors)
            self.validation_cache[workflow_hash] = result
            return result
        except Exception as e:
            errors.append(f"éªŒè¯è¿‡ç¨‹é”™è¯¯: {str(e)}")
            result = ValidationResult(is_valid=False, errors=errors)
            self.validation_cache[workflow_hash] = result
            return result

    def _custom_validation(self, data: Dict, errors: List[str], warnings: List[str]):
        """è‡ªå®šä¹‰éªŒè¯è§„åˆ™"""
        # æ£€æŸ¥èŠ‚ç‚¹IDå”¯ä¸€æ€§
        node_ids = set()
        for node in data.get('nodes', []):
            node_id = node.get('id')
            if node_id:
                if node_id in node_ids:
                    errors.append(f"é‡å¤çš„èŠ‚ç‚¹ID: {node_id}")
                node_ids.add(node_id)

        # æ£€æŸ¥è¿æ¥å¼•ç”¨
        connections = data.get('connections', {})
        all_node_names = {node.get('name') for node in data.get('nodes', []) if node.get('name')}

        for source_node, connection_info in connections.items():
            if source_node not in all_node_names:
                warnings.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„æºèŠ‚ç‚¹: {source_node}")

            for connection_list in connection_info.values():
                for connection in connection_list:
                    for link in connection:
                        target_node = link.get('node')
                        if target_node and target_node not in all_node_names:
                            warnings.append(f"è¿æ¥å¼•ç”¨äº†ä¸å­˜åœ¨çš„ç›®æ ‡èŠ‚ç‚¹: {target_node}")

    def validate_semantics(self, workflow_json: str, user_input: str) -> ValidationResult:
        """è¯­ä¹‰éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦æ»¡è¶³ç”¨æˆ·éœ€æ±‚"""
        # todo åç»­æ‰©å±•
        errors = []
        warnings = []

        try:
            data = json5.loads(workflow_json)

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®èŠ‚ç‚¹ç±»å‹
            node_types = {node.get('type', '') for node in data.get('nodes', [])}

            # æ ¹æ®ç”¨æˆ·è¾“å…¥æ£€æŸ¥å…³é”®åŠŸèƒ½
            user_input_lower = user_input.lower()

            if any(keyword in user_input_lower for keyword in ['å®šæ—¶', 'æ¯å¤©', 'schedule', 'cron']):
                if not any('schedule' in node_type.lower() for node_type in node_types):
                    warnings.append("ç”¨æˆ·éœ€æ±‚åŒ…å«å®šæ—¶åŠŸèƒ½ï¼Œä½†æœªæ‰¾åˆ°å®šæ—¶è§¦å‘å™¨èŠ‚ç‚¹")

            if any(keyword in user_input_lower for keyword in ['http', 'api', 'è¯·æ±‚']):
                if not any('http' in node_type.lower() for node_type in node_types):
                    warnings.append("ç”¨æˆ·éœ€æ±‚åŒ…å«HTTPè¯·æ±‚ï¼Œä½†æœªæ‰¾åˆ°HTTPè¯·æ±‚èŠ‚ç‚¹")

            if any(keyword in user_input_lower for keyword in ['é‚®ä»¶', 'email', 'å‘é€']):
                if not any('email' in node_type.lower() for node_type in node_types):
                    warnings.append("ç”¨æˆ·éœ€æ±‚åŒ…å«é‚®ä»¶åŠŸèƒ½ï¼Œä½†æœªæ‰¾åˆ°é‚®ä»¶å‘é€èŠ‚ç‚¹")

            return  ValidationResult(is_valid=True, errors=errors, warnings=warnings)

        except Exception as e:
            return ValidationResult(is_valid=False, errors=[f"è¯­ä¹‰éªŒè¯é”™è¯¯: {str(e)}"])

    def match_error_pattern(self, error_message: str) -> Optional[ErrorPattern]:
        """åŒ¹é…é”™è¯¯æ¨¡å¼"""
        for pattern in sorted(self.error_patterns, key=lambda x: x.priority, reverse=True):
            if re.search(pattern.error_pattern, error_message, re.IGNORECASE):
                return pattern
        return None

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    async def generate_workflow(self, user_input: str, error_history: List[str] = None) -> str:
        """ç”Ÿæˆn8nå·¥ä½œæµJSON"""
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"ç”¨æˆ·éœ€æ±‚: {user_input}")
        ]

        print(f"messages: {messages}")

        if error_history:
            error_context = "\n".join(
                [f"ç¬¬{i + 1}æ¬¡é”™è¯¯: {error}" for i, error in enumerate(error_history[-5:])])  # åªä¿ç•™æœ€è¿‘3ä¸ªé”™è¯¯
            messages.append(HumanMessage(content=f"ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯:\n{error_context}\nè¯·æ ¹æ®è¿™äº›é”™è¯¯ä¿®æ­£å·¥ä½œæµã€‚"))

        # æ·»åŠ é”™è¯¯æ¨¡å¼å»ºè®®
        if error_history:
            last_error = error_history[-1]
            matched_pattern = self.match_error_pattern(last_error)
            if matched_pattern:
                messages.append(HumanMessage(content=f"é”™è¯¯æ¨¡å¼å»ºè®®: {matched_pattern.solution}"))

        response = await self.llm.ainvoke(messages)
        print(f"response1111: {response}")
        try:
            workflow_json = self._extract_json_from_response(response.content)
            # å¤šé˜¶æ®µéªŒè¯
            syntax_result = self.validate_syntax(workflow_json)
            if not syntax_result:
                raise ValueError(f"è¯­æ³•éªŒè¯å¤±è´¥: {', '.join(syntax_result.errors)}")

            schema_result = self.validate_schema(workflow_json)
            if not schema_result:
                raise ValueError(f"æ¨¡å¼éªŒè¯å¤±è´¥: {', '.join(schema_result.errors)}")

            semantic_result = self.validate_semantics(workflow_json, user_input)
            if semantic_result.warnings:
                logger.warning(f"è¯­ä¹‰è­¦å‘Š: {', '.join(semantic_result.warnings)}")

            return workflow_json

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"ç”Ÿæˆçš„å·¥ä½œæµéªŒè¯å¤±è´¥: {e}")
            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œè®©LLMé‡æ–°ç”Ÿæˆ
            return await self._regenerate_with_validation_feedback(user_input, str(e), error_history)



    def _extract_json_from_response(self, text: str) -> str:
        """ä»LLMå“åº”ä¸­æå–JSONå†…å®¹"""
        # æŸ¥æ‰¾JSONå¼€å§‹å’Œç»“æŸçš„ä½ç½®
        start = text.find('{')
        end = text.rfind('}') + 1

        if start != -1 and end != -1:
            json_str = text[start:end]
            # æ¸…ç†JSONå­—ç¬¦ä¸²
            json_str = re.sub(r',\s*]', ']', json_str)  # ä¿®å¤å°¾éšé€—å·
            json_str = re.sub(r',\s*}', '}', json_str)
            return json_str
        return text

    @retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=1, min=2, max=5))
    async def _regenerate_with_validation_feedback(self, user_input: str, error_message: str,
                                             error_history: List[str]) -> str:
        """æ ¹æ®éªŒè¯åé¦ˆé‡æ–°ç”Ÿæˆ"""
        feedback_prompt = f"""
ä¹‹å‰çš„ç”¨æˆ·éœ€æ±‚: {user_input}

ç”Ÿæˆçš„å·¥ä½œæµéªŒè¯å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:
{error_message}

ä¹‹å‰çš„é”™è¯¯å†å²:
{chr(10).join(error_history[-2:] if error_history else [])}

è¯·æ ¹æ®éªŒè¯é”™è¯¯é‡æ–°ç”Ÿæˆæ­£ç¡®çš„å·¥ä½œæµJSONã€‚ç¡®ä¿:
1. ä¿®å¤æ‰€æœ‰JSONè¯­æ³•é”™è¯¯
2. ç¡®ä¿ç¬¦åˆn8n schemaè§„èŒƒ
3. æ£€æŸ¥æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
4. ç¡®ä¿èŠ‚ç‚¹ç±»å‹æ­£ç¡®
5. ç¡®ä¿èŠ‚ç‚¹ä¹‹é—´å»ºç«‹æ­£ç¡®çš„è¿æ¥å…³ç³»

åªè¿”å›ä¿®æ­£åçš„JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡æœ¬ã€‚
"""

        response = await self.llm.ainvoke([
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªn8nå·¥ä½œæµè°ƒè¯•ä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®éªŒè¯é”™è¯¯æä¾›ä¿®æ­£æ–¹æ¡ˆã€‚"),
            HumanMessage(content=feedback_prompt)
        ])

        return self._extract_json_from_response(response.content)

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=5))
    async def deploy_to_n8n(self, workflow_json: str) -> Dict:
        """éƒ¨ç½²å·¥ä½œæµåˆ°n8n"""
        url = f"{self.n8n_base_url}/api/v1/workflows"
        headers = {
            "Content-Type": "application/json",
            "X-N8N-API-KEY": self.n8n_api_key
        }

        try:
            # å…ˆè¿›è¡Œæœ€ç»ˆéªŒè¯
            validation_result = self.validate_schema(workflow_json)
            if not validation_result:
                return {
                    "success": False,
                    "error": f"éƒ¨ç½²å‰éªŒè¯å¤±è´¥: {', '.join(validation_result.errors)}",
                    "stage": "pre_deployment_validation"
                }

            workflow_data = json5.loads(workflow_json)
            # å¼‚æ­¥å‘é€HTTPè¯·æ±‚ï¼ˆæ›¿æ¢requests.postä¸ºaiohttp.postï¼‰
            response = await self.session.post(
                url,
                json=workflow_data,
                headers=headers,
                timeout=30  # å¼‚æ­¥è¶…æ—¶è®¾ç½®
            )
            # å¼‚æ­¥è§£æå“åº”JSON
            response_data = await response.json()
            print(f"workflow_data: {workflow_data}")
            print("rrrrrrrrr:", response_data)

            if response.status in [200, 201]:
                # è·å–åˆ›å»ºçš„å·¥ä½œæµIDè¿›è¡ŒäºŒæ¬¡éªŒè¯
                workflow_id = response_data.get('id')
                if workflow_id:
                    # éªŒè¯å·¥ä½œæµæ˜¯å¦çœŸæ­£å¯ç”¨
                    verify_result = await self.verify_workflow(workflow_id)
                    print("verify workflow:", verify_result)
                    if not verify_result['success']:
                        # åˆ é™¤æœ‰é—®é¢˜çš„å·¥ä½œæµ
                        await  self.delete_workflow(workflow_id)
                        return {
                            "success": False,
                            "error": f"å·¥ä½œæµåˆ›å»ºæˆåŠŸä½†éªŒè¯å¤±è´¥: {verify_result['error']}",
                            "workflow_id": workflow_id
                        }
                return {
                    "success": True,
                    "data": response_data,
                    "stage": "deployment"
                }
            else:
                error_msg = f"éƒ¨ç½²å¤±è´¥: {response.status} - {response_data.get('message')}"
                # å­¦ä¹ æ–°çš„é”™è¯¯æ¨¡å¼
                self._learn_from_error(error_msg)
                return {
                    "success": False,
                    "error": error_msg,
                    "stage": "deployment"
                }

        except aiohttp.ClientError as e:
            error_msg = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}"
            return {"success": False, "error": error_msg, "stage": "network"}
        except json.JSONDecodeError as e:
            error_msg = f"JSONè§£æé”™è¯¯: {str(e)}"
            return {"success": False, "error": error_msg, "stage": "parsing"}

    async def verify_workflow(self, workflow_id: str) -> Dict:
        """éªŒè¯å·¥ä½œæµæ˜¯å¦çœŸæ­£å¯ç”¨"""
        url = f"{self.n8n_base_url}/api/v1/workflows/{workflow_id}/activate"
        headers = {"X-N8N-API-KEY": self.n8n_api_key, "Content-Type": "application/json"}

        try:
            response = await self.session.post(url, json={}, headers=headers, timeout=10)
            response_data = await response.json()
            print(f"verify response: {response_data}")
            if response.status == 200:
                # å¯é¢å¤–æ£€æŸ¥å“åº”ä¸­çš„activeå­—æ®µæ˜¯å¦ä¸ºtrueï¼Œç¡®è®¤æ¿€æ´»æˆåŠŸ
                if response_data.get("active") is True:
                    return {"success": True, "message": "å·¥ä½œæµæ¿€æ´»æˆåŠŸ"}
                else:
                    return {"success": False, "error": f"å·¥ä½œæµçŠ¶æ€æœªå˜ä¸ºæ¿€æ´»:{response_data.get("message")}"}
            return {"success": False, "error": f"è·å–å·¥ä½œæµå¤±è´¥:{response.status} - {response_data.get("message")}"}
        except Exception as e:
            return {"success": False, "error": f"éªŒè¯é”™è¯¯: {str(e)}"}

    async def delete_workflow(self, workflow_id: str):
        """åˆ é™¤å·¥ä½œæµ"""
        url = f"{self.n8n_base_url}/api/v1/workflows/{workflow_id}"
        headers = {"X-N8N-API-KEY": self.n8n_api_key}

        try:
            await self.session.delete(url, headers=headers, timeout=10)
        except aiohttp.ClientError:
            pass

    def _learn_from_error(self, error_message: str):
        """ä»é”™è¯¯ä¸­å­¦ä¹ æ–°çš„æ¨¡å¼"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å·²çŸ¥æ¨¡å¼
        existing_pattern = self.match_error_pattern(error_message)
        if not existing_pattern:
            # æå–é”™è¯¯å…³é”®è¯
            keywords = re.findall(r'\b[a-zA-Z]{4,}\b', error_message)
            if keywords:
                new_pattern = ErrorPattern(
                    error_pattern=f".*{'|'.join(keywords[:3])}.*",
                    solution=f"å¤„ç†{', '.join(keywords[:2])}ç›¸å…³é”™è¯¯",
                    priority=2
                )
                self.error_patterns.append(new_pattern)
                logger.info(f"å­¦ä¹ åˆ°æ–°çš„é”™è¯¯æ¨¡å¼: {new_pattern.error_pattern}")

    def _clean_workflow_json(self, workflow_config: Dict) -> Dict:
        """æ¸…ç†å’Œè§„èŒƒåŒ–å·¥ä½œæµ JSONï¼Œç¡®ä¿å…¶ç¬¦åˆ n8n è¦æ±‚"""
        print("\næ­¥éª¤4: æ¸…ç†å’Œè§„èŒƒåŒ–å·¥ä½œæµ JSON...")

        # éªŒè¯èŠ‚ç‚¹å’Œè¿æ¥
        if not workflow_config.get("nodes"):
            raise ValueError("å·¥ä½œæµå¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªèŠ‚ç‚¹")

        if not workflow_config.get("connections"):
            raise ValueError("å·¥ä½œæµå¿…é¡»åŒ…å«èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»")

        print("æ¸…ç†å‰çš„å·¥ä½œæµä¿¡æ¯:")
        print(f"  èŠ‚ç‚¹æ•°é‡: {len(workflow_config.get('nodes', []))}")
        print(f"  è¿æ¥æ•°é‡: {len(workflow_config.get('connections', {}))}")

        nodes = workflow_config.get("nodes", [])

        for i, node in enumerate(nodes):
            print(f"  æ¸…ç†èŠ‚ç‚¹ {i + 1}: {node.get('name', 'Unknown')} ({node.get('type', 'Unknown')})")
            parameters = node.get("parameters", {})

            # éªŒè¯å‚æ•°æ˜¯å¦ç¬¦åˆè§„èŒƒ
            node_type = node.get("type")
            # current_version = node.get("typeVersion")

            if node_type in self.base_nodes:
                node_spec = self.base_nodes[node_type]
                for param_name, param_value in parameters.items():
                    # æŸ¥æ‰¾å¯¹åº”çš„å‚æ•°è§„èŒƒ
                    param_spec = None
                    for spec_param in node_spec.get('parameters', []):
                        if spec_param['name'] == param_name:
                            param_spec = spec_param
                            break

                    if param_spec:
                        # æ£€æŸ¥optionsç±»å‹å‚æ•°çš„å€¼æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
                        if param_spec.get('type') == 'options' and param_spec.get('options'):
                            if param_value not in param_spec['options']:
                                print(f"    å‚æ•° {param_name} çš„å€¼ '{param_value}' ä¸åœ¨å…è®¸èŒƒå›´å†…")
                                print(f"      å…è®¸çš„å€¼: {param_spec['options']}")
                                # ä½¿ç”¨é»˜è®¤å€¼æˆ–ç¬¬ä¸€ä¸ªå…è®¸å€¼
                                if param_spec.get('default') in param_spec['options']:
                                    parameters[param_name] = param_spec['default']
                                    print(f"      å·²ä¿®æ­£ä¸ºé»˜è®¤å€¼: {param_spec['default']}")
                                else:
                                    parameters[param_name] = param_spec['options'][0]
                                    print(f"      å·²ä¿®æ­£ä¸ºç¬¬ä¸€ä¸ªå…è®¸å€¼: {param_spec['options'][0]}")

            # 1. å°†ç©ºçš„ 'options: {}' è½¬æ¢ä¸º 'options: []'
            if "options" in parameters and isinstance(parameters["options"], dict) and not parameters["options"]:
                parameters["options"] = []  # è½¬æ¢ä¸ºç©ºåˆ—è¡¨
                print("    è½¬æ¢ç©ºoptionså¯¹è±¡ä¸ºæ•°ç»„")

            # 2. ç¡®ä¿é›†åˆç±»å‹å‚æ•°æ˜¯ [] è€Œä¸æ˜¯ {}
            for param_name, param_value in parameters.items():
                if isinstance(param_value, dict) and not param_value:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ n8n ä¸­å¸¸è§çš„é›†åˆç±»å‹å‚æ•°
                    if param_name in ["bodyParameters", "conditions"]:
                        # æ£€æŸ¥å…¶å­å­—æ®µ
                        if "values" in param_value and isinstance(param_value["values"], dict) and not param_value[
                            "values"]:
                            param_value["values"] = []
                            print(f"    è½¬æ¢ {param_name}.values ä¸ºç©ºæ•°ç»„")
                        if "boolean" in param_value and isinstance(param_value["boolean"], dict) and not param_value[
                            "boolean"]:
                            param_value["boolean"] = []
                            print(f"    è½¬æ¢ {param_name}.boolean ä¸ºç©ºæ•°ç»„")

            node["parameters"] = parameters
        workflow_config["nodes"] = nodes

        # ç§»é™¤ n8n API åˆ›å»ºå·¥ä½œæµæ—¶ä¸å…è®¸çš„é¡¶å±‚å±æ€§
        properties_to_remove = ["versionId", "id", "staticData", "meta", "pinData", "createdAt", "updatedAt",
                                "triggerCount","tags"]
        for prop in properties_to_remove:
            if prop in workflow_config:
                del workflow_config[prop]
                print(f"  ç§»é™¤ä¸å…è®¸çš„å±æ€§: {prop}")

        # ç§»é™¤ 'active' å±æ€§ï¼Œå› ä¸ºå®ƒåœ¨åˆ›å»ºæ—¶é€šå¸¸æ˜¯åªè¯»çš„æˆ–ä¸å…è®¸è®¾ç½®
        if "active" in workflow_config:
            del workflow_config["active"]
            print("  ç§»é™¤activeå±æ€§")

        print("å·¥ä½œæµ JSON æ¸…ç†å®Œæˆ")
        return workflow_config


def create_workflow_agent():
    """åˆ›å»ºLangGraphæ™ºèƒ½ä½“"""
    from langgraph.graph import StateGraph, END

    agent = N8NWorkflowAgent()

    # åˆ›å»ºå›¾
    workflow = StateGraph(AgentState)

    # å®šä¹‰èŠ‚ç‚¹ - ç”Ÿæˆå·¥ä½œæµ
    async def generate_node(state: AgentState):
        """ç”Ÿæˆå·¥ä½œæµèŠ‚ç‚¹"""
        current_iteration = state.iteration_count
        logger.info(f"ç¬¬{state.iteration_count + 1}æ¬¡ç”Ÿæˆå·¥ä½œæµ...")

        workflow_json = await agent.generate_workflow(
            state.user_input,
            state.error_messages
        )

        # è¿›è¡Œå¤šé˜¶æ®µéªŒè¯
        validation_results = []

        # è¯­æ³•éªŒè¯
        syntax_result = agent.validate_syntax(workflow_json)
        validation_results.append(syntax_result)

        if syntax_result:
            # æ¨¡å¼éªŒè¯
            schema_result = agent.validate_schema(workflow_json)
            validation_results.append(schema_result)

            if schema_result:
                # è¯­ä¹‰éªŒè¯
                semantic_result = agent.validate_semantics(workflow_json, state.user_input)
                validation_results.append(semantic_result)

        return {
            "workflow_json": workflow_json,
            "iteration_count": current_iteration + 1,
            "validation_results": validation_results,
            "current_stage": "generation"
        }

    # å®šä¹‰èŠ‚ç‚¹ - éƒ¨ç½²å·¥ä½œæµï¼ˆä¾èµ–agentå®ä¾‹çš„_clean_workflow_jsonæ–¹æ³•ï¼‰
    async def deploy_node(state: AgentState):
        """éƒ¨ç½²å·¥ä½œæµèŠ‚ç‚¹"""
        logger.info("éƒ¨ç½²å·¥ä½œæµåˆ°n8n...")
        current_iteration = state.iteration_count
        # è§£æç”Ÿæˆçš„å·¥ä½œæµJSON
        workflow1 = json5.loads(state.workflow_json)
        # è°ƒç”¨agentçš„æ¸…ç†æ–¹æ³•ï¼ˆä¿®æ­£ï¼šé€šè¿‡agentå®ä¾‹è°ƒç”¨ï¼Œè€Œéå…¨å±€å‡½æ•°ï¼‰
        stared_workflow = agent._clean_workflow_json(workflow1)

        # ä¿å­˜å·¥ä½œæµ
        print("\næ­¥éª¤5: ä¿å­˜å·¥ä½œæµé…ç½®åˆ°configç›®å½•...")
        try:
            save_dir = os.path.join(os.path.dirname(__file__), 'config')
            os.makedirs(save_dir, exist_ok=True)
            print(f"  ç¡®ä¿ç›®å½•å­˜åœ¨: {save_dir}")

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³é¿å…é‡å¤ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            config_file_path = os.path.join(save_dir, f"{timestamp}.json")

            # åªä¿å­˜n8nå·¥ä½œæµé…ç½®ï¼ˆä¿®æ­£ï¼šæ­£ç¡®è°ƒç”¨json.dumpï¼‰
            with open(config_file_path, 'w', encoding='utf-8') as f:
                json.dump(stared_workflow, f, ensure_ascii=False, indent=2)

            print(f"  å·¥ä½œæµé…ç½®å·²ä¿å­˜åˆ°: {config_file_path}")

        except Exception as e:
            print(f"  ä¿å­˜å·¥ä½œæµé…ç½®å¤±è´¥: {e}")

        # éƒ¨ç½²å·¥ä½œæµï¼ˆä¿®æ­£ï¼šå°†æ¸…ç†åçš„å­—å…¸è½¬ä¸ºJSONå­—ç¬¦ä¸²ï¼‰
        result = await agent.deploy_to_n8n(json.dumps(stared_workflow, ensure_ascii=False, indent=2))
        print(f"result: {result}")
        if result['success']:
            logger.info("éƒ¨ç½²æˆåŠŸ!")
            return {
                "deployment_result": result,
                "iteration_count": current_iteration,
                "current_stage": "deployment_success"
            }
        else:
            logger.warning(f"éƒ¨ç½²å¤±è´¥: {result['error']}")
            return {
                "deployment_result": result,
                "error_messages": state.error_messages + [result['error']],
                "iteration_count": state.iteration_count ,
                "current_stage": "deployment_failed"
            }

    def should_continue(state: AgentState):
        """å†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£"""
        if state.deployment_result.get('success', False):
            logger.info("å·¥ä½œæµéƒ¨ç½²æˆåŠŸï¼Œç»“æŸæµç¨‹")
            return END
        elif state.iteration_count >= state.max_iterations:
            logger.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç»“æŸæµç¨‹")
            return END
        else:
            # æ£€æŸ¥éªŒè¯ç»“æœï¼Œå¦‚æœæœ‰ä¸¥é‡é”™è¯¯ç›´æ¥é‡æ–°ç”Ÿæˆ
            for validation_result in state.validation_results:
                if validation_result.errors:
                    logger.info("éªŒè¯å‘ç°é”™è¯¯ï¼Œé‡æ–°ç”Ÿæˆ...")
                    return "generate"

            logger.info("ç»§ç»­éƒ¨ç½²æµç¨‹...")
            return "generate"

    # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    workflow.add_node("generate", generate_node)
    workflow.add_node("deploy", deploy_node)

    workflow.set_entry_point("generate")
    workflow.add_conditional_edges(
        "generate",
        # ä¿®æ­£ï¼šæ¡ä»¶åˆ¤æ–­é€»è¾‘ï¼ˆç¡®ä¿workflow_jsonå­˜åœ¨ï¼‰
        lambda state: "deploy" if state.workflow_json.strip() else "generate",
        {
            "generate": "generate",
            "deploy": "deploy"
        }
    )

    workflow.add_conditional_edges(
        "deploy",
        should_continue,
        {
            "generate": "generate",
            END: END
        }
    )

    return workflow.compile(), agent


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    # åˆ›å»ºæ™ºèƒ½ä½“
    app,agent = create_workflow_agent()

    # åˆå§‹çŠ¶æ€
    initial_state = AgentState(
        user_input = "åˆ›å»ºä¸€ä¸ªæ¯æ—¥é”€å”®æŠ¥å‘Šå·¥ä½œæµï¼Œä»CRMã€æ”¯ä»˜ç³»ç»Ÿå’Œåˆ†æå¹³å°è·å–æ•°æ®ï¼Œç„¶åå‘é€é‚®ä»¶æŠ¥å‘Š",
        #user_input="åˆ›å»ºä¸€ä¸ª n8n å·¥ä½œæµï¼Œå½“æœ‰æ–°è®¢å•è¿›å…¥æ—¶è§¦å‘ï¼Œæ›´æ–°æˆ‘ä»¬æ•°æ®åº“ä¸­çš„åº“å­˜ï¼Œå‘å®¢æˆ·å‘é€ç¡®è®¤é‚®ä»¶ï¼Œå¹¶ç”Ÿæˆè¿è¾“æ ‡ç­¾ã€‚",
            workflow_json = "",
        deployment_result = {},
        error_messages = [],
        iteration_count = 0,
        max_iterations = 5,
        validation_results = [],
        current_stage = "start"
    )

    # æ‰§è¡Œæ™ºèƒ½ä½“
    try:
        final_state = await app.ainvoke(initial_state)
        # ğŸ”µ å…³é”®ï¼šæ ¡éªŒ final_state ç±»å‹ï¼Œç¡®ä¿æ˜¯ AgentState å¯¹è±¡
        if not isinstance(final_state, AgentState):
            # è‹¥ä¸ºå­—å…¸ï¼Œå°è¯•è½¬ä¸º AgentStateï¼ˆå…¼å®¹æ„å¤–è½¬æ¢çš„æƒ…å†µï¼‰
            if isinstance(final_state, dict):
                final_state = AgentState(**final_state)
            else:
                raise TypeError(f"final_state ç±»å‹é”™è¯¯ï¼Œåº”ä¸º AgentStateï¼Œå®é™…ä¸º {type(final_state)}")

        if final_state.deployment_result.get('success', False):
            print("âœ… å·¥ä½œæµéƒ¨ç½²æˆåŠŸ!")
            # åˆ é™¤æˆåŠŸéƒ¨ç½²çš„å·¥ä½œæµ ç„¶ååˆç†çš„jsonç»™tså†è¿›è¡Œç»Ÿä¸€éƒ¨ç½²å¤„ç†
            workflow_id = final_state.deployment_result['data'].get('id')
            workflow_json = final_state.workflow_json
            await  agent.delete_workflow(workflow_id)
            print("======>>>>>",workflow_json)
            print(final_state.get("workflow_json"))
            print(f"å·¥ä½œæµID: {final_state.deployment_result['data'].get('id', 'æœªçŸ¥')}")
            print(f"æ€»è¿­ä»£æ¬¡æ•°: {final_state.iteration_count}")
        else:
            print("âŒ å·¥ä½œæµéƒ¨ç½²å¤±è´¥")
            print(f"æœ€ç»ˆé”™è¯¯: {final_state.deployment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print(f"æ€»å…±å°è¯•æ¬¡æ•°: {final_state.iteration_count}")
            print(f"é”™è¯¯å†å²: {final_state.error_messages}")

    except Exception as e:
        print(f"æ™ºèƒ½ä½“æ‰§è¡Œå‡ºé”™: {e}")
    finally:
        # ğŸ”µ æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½å…³é—­ä¼šè¯å’Œè¿æ¥æ± 
        if agent:
            # å…³é—­ä¼šè¯ï¼ˆä¼šé‡Šæ”¾æ‰€æœ‰è¿æ¥ï¼‰
            if not agent.session.closed:
                await agent.session.close()
            # å…³é—­è¿æ¥æ± 
            await agent.connector.close()
            print("å·²å…³é—­æ‰€æœ‰å¼‚æ­¥è¿æ¥å’Œä¼šè¯")


if __name__ == "__main__":
    asyncio.run(main())